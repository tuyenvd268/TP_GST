{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io.wavfile import write\n",
    "import glob\n",
    "import os\n",
    "import matplotlib\n",
    "import os\n",
    "import shutil\n",
    "import torch\n",
    "from torch.nn.utils import weight_norm\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "DEVICE = None\n",
    "MAX_WAV_VALUE = 32768.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttrDict(dict):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(AttrDict, self).__init__(*args, **kwargs)\n",
    "        self.__dict__ = self\n",
    "\n",
    "\n",
    "def build_env(config, config_name, path):\n",
    "    t_path = os.path.join(path, config_name)\n",
    "    if config != t_path:\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "        shutil.copyfile(config, os.path.join(path, config_name))\n",
    "\n",
    "\n",
    "def plot_spectrogram(spectrogram):\n",
    "    fig, ax = plt.subplots(figsize=(10, 2))\n",
    "    im = ax.imshow(spectrogram, aspect=\"auto\", origin=\"lower\",\n",
    "                   interpolation='none')\n",
    "    plt.colorbar(im, ax=ax)\n",
    "\n",
    "    fig.canvas.draw()\n",
    "    plt.close()\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "def init_weights(m, mean=0.0, std=0.01):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        m.weight.data.normal_(mean, std)\n",
    "\n",
    "\n",
    "def apply_weight_norm(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        weight_norm(m)\n",
    "\n",
    "\n",
    "def get_padding(kernel_size, dilation=1):\n",
    "    return int((kernel_size*dilation - dilation)/2)\n",
    "\n",
    "\n",
    "def load_checkpoint(filepath, device):\n",
    "    assert os.path.isfile(filepath)\n",
    "    print(\"Loading '{}'\".format(filepath))\n",
    "    checkpoint_dict = torch.load(filepath, map_location=device)\n",
    "    print(\"Complete.\")\n",
    "    return checkpoint_dict\n",
    "\n",
    "\n",
    "def save_checkpoint(filepath, obj):\n",
    "    print(\"Saving checkpoint to {}\".format(filepath))\n",
    "    torch.save(obj, filepath)\n",
    "    print(\"Complete.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.nn import Conv1d, ConvTranspose1d, AvgPool1d, Conv2d\n",
    "from torch.nn.utils import weight_norm, remove_weight_norm, spectral_norm\n",
    "\n",
    "LRELU_SLOPE = 0.1\n",
    "\n",
    "\n",
    "class ResBlock1(torch.nn.Module):\n",
    "    def __init__(self, h, channels, kernel_size=3, dilation=(1, 3, 5)):\n",
    "        super(ResBlock1, self).__init__()\n",
    "        self.h = h\n",
    "        self.convs1 = nn.ModuleList([\n",
    "            weight_norm(Conv1d(channels, channels, kernel_size, 1, dilation=dilation[0],\n",
    "                               padding=get_padding(kernel_size, dilation[0]))),\n",
    "            weight_norm(Conv1d(channels, channels, kernel_size, 1, dilation=dilation[1],\n",
    "                               padding=get_padding(kernel_size, dilation[1]))),\n",
    "            weight_norm(Conv1d(channels, channels, kernel_size, 1, dilation=dilation[2],\n",
    "                               padding=get_padding(kernel_size, dilation[2])))\n",
    "        ])\n",
    "        self.convs1.apply(init_weights)\n",
    "\n",
    "        self.convs2 = nn.ModuleList([\n",
    "            weight_norm(Conv1d(channels, channels, kernel_size, 1, dilation=1,\n",
    "                               padding=get_padding(kernel_size, 1))),\n",
    "            weight_norm(Conv1d(channels, channels, kernel_size, 1, dilation=1,\n",
    "                               padding=get_padding(kernel_size, 1))),\n",
    "            weight_norm(Conv1d(channels, channels, kernel_size, 1, dilation=1,\n",
    "                               padding=get_padding(kernel_size, 1)))\n",
    "        ])\n",
    "        self.convs2.apply(init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for c1, c2 in zip(self.convs1, self.convs2):\n",
    "            xt = F.leaky_relu(x, LRELU_SLOPE)\n",
    "            xt = c1(xt)\n",
    "            xt = F.leaky_relu(xt, LRELU_SLOPE)\n",
    "            xt = c2(xt)\n",
    "            x = xt + x\n",
    "        return x\n",
    "\n",
    "    def remove_weight_norm(self):\n",
    "        for l in self.convs1:\n",
    "            remove_weight_norm(l)\n",
    "        for l in self.convs2:\n",
    "            remove_weight_norm(l)\n",
    "\n",
    "\n",
    "class ResBlock2(torch.nn.Module):\n",
    "    def __init__(self, h, channels, kernel_size=3, dilation=(1, 3)):\n",
    "        super(ResBlock2, self).__init__()\n",
    "        self.h = h\n",
    "        self.convs = nn.ModuleList([\n",
    "            weight_norm(Conv1d(channels, channels, kernel_size, 1, dilation=dilation[0],\n",
    "                               padding=get_padding(kernel_size, dilation[0]))),\n",
    "            weight_norm(Conv1d(channels, channels, kernel_size, 1, dilation=dilation[1],\n",
    "                               padding=get_padding(kernel_size, dilation[1])))\n",
    "        ])\n",
    "        self.convs.apply(init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for c in self.convs:\n",
    "            xt = F.leaky_relu(x, LRELU_SLOPE)\n",
    "            xt = c(xt)\n",
    "            x = xt + x\n",
    "        return x\n",
    "\n",
    "    def remove_weight_norm(self):\n",
    "        for l in self.convs:\n",
    "            remove_weight_norm(l)\n",
    "\n",
    "\n",
    "class Generator(torch.nn.Module):\n",
    "    def __init__(self, h):\n",
    "        super(Generator, self).__init__()\n",
    "        self.h = h\n",
    "        self.num_kernels = len(h.resblock_kernel_sizes)\n",
    "        self.num_upsamples = len(h.upsample_rates)\n",
    "        self.conv_pre = weight_norm(Conv1d(80, h.upsample_initial_channel, 7, 1, padding=3))\n",
    "        resblock = ResBlock1 if h.resblock == '1' else ResBlock2\n",
    "\n",
    "        self.ups = nn.ModuleList()\n",
    "        for i, (u, k) in enumerate(zip(h.upsample_rates, h.upsample_kernel_sizes)):\n",
    "            self.ups.append(weight_norm(\n",
    "                ConvTranspose1d(h.upsample_initial_channel//(2**i), h.upsample_initial_channel//(2**(i+1)),\n",
    "                                k, u, padding=(k-u)//2)))\n",
    "\n",
    "        self.resblocks = nn.ModuleList()\n",
    "        for i in range(len(self.ups)):\n",
    "            ch = h.upsample_initial_channel//(2**(i+1))\n",
    "            for j, (k, d) in enumerate(zip(h.resblock_kernel_sizes, h.resblock_dilation_sizes)):\n",
    "                self.resblocks.append(resblock(h, ch, k, d))\n",
    "\n",
    "        self.conv_post = weight_norm(Conv1d(ch, 1, 7, 1, padding=3))\n",
    "        self.ups.apply(init_weights)\n",
    "        self.conv_post.apply(init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_pre(x)\n",
    "        for i in range(self.num_upsamples):\n",
    "            x = F.leaky_relu(x, LRELU_SLOPE)\n",
    "            x = self.ups[i](x)\n",
    "            xs = None\n",
    "            for j in range(self.num_kernels):\n",
    "                if xs is None:\n",
    "                    xs = self.resblocks[i*self.num_kernels+j](x)\n",
    "                else:\n",
    "                    xs += self.resblocks[i*self.num_kernels+j](x)\n",
    "            x = xs / self.num_kernels\n",
    "        x = F.leaky_relu(x)\n",
    "        x = self.conv_post(x)\n",
    "        x = torch.tanh(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def remove_weight_norm(self):\n",
    "        print('Removing weight norm...')\n",
    "        for l in self.ups:\n",
    "            remove_weight_norm(l)\n",
    "        for l in self.resblocks:\n",
    "            l.remove_weight_norm()\n",
    "        remove_weight_norm(self.conv_pre)\n",
    "        remove_weight_norm(self.conv_post)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"resblock\": \"1\",\n",
    "    \"num_gpus\": 0,\n",
    "    \"batch_size\": 16,\n",
    "    \"learning_rate\": 0.0002,\n",
    "    \"adam_b1\": 0.8,\n",
    "    \"adam_b2\": 0.99,\n",
    "    \"lr_decay\": 0.999,\n",
    "    \"seed\": 1234,\n",
    "\n",
    "    \"upsample_rates\": [8,8,2,2],\n",
    "    \"upsample_kernel_sizes\": [16,16,4,4],\n",
    "    \"upsample_initial_channel\": 512,\n",
    "    \"resblock_kernel_sizes\": [3,7,11],\n",
    "    \"resblock_dilation_sizes\": [[1,3,5], [1,3,5], [1,3,5]],\n",
    "\n",
    "    \"segment_size\": 8192,\n",
    "    \"num_mels\": 80,\n",
    "    \"num_freq\": 1025,\n",
    "    \"n_fft\": 1024,\n",
    "    \"hop_size\": 256,\n",
    "    \"win_size\": 1024,\n",
    "\n",
    "    \"sampling_rate\": 22050,\n",
    "\n",
    "    \"fmin\": 0,\n",
    "    \"fmax\": 8000,\n",
    "    \"fmax_for_loss\": \"null\",\n",
    "\n",
    "    \"num_workers\": 4,\n",
    "\n",
    "    \"dist_config\": {\n",
    "        \"dist_backend\": \"nccl\",\n",
    "        \"dist_url\": \"tcp://localhost:54321\",\n",
    "        \"world_size\": 1\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing weight norm...\n"
     ]
    }
   ],
   "source": [
    "vocoder_config = AttrDict(config)\n",
    "vocoder = Generator(vocoder_config)\n",
    "vocoder.load_state_dict(torch.load(\"ckpts/generator_universal.pth.tar\", map_location=torch.device('cpu'))['generator'])\n",
    "vocoder.eval()\n",
    "vocoder.remove_weight_norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14, 400])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp_gst_mel = np.load(\"train-set/mel/000000.npy\")\n",
    "tp_gst_mel = torch.from_numpy(tp_gst_mel)\n",
    "tp_gst_mel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_hifigan_format(tp_gst_mel):\n",
    "    maxval, minval = 3.0, np.log(1e-5)\n",
    "    mel = tp_gst_mel.reshape(-1, 80).T * (maxval - minval) + minval\n",
    "    \n",
    "    return mel\n",
    "\n",
    "mel = convert_to_hifigan_format(tp_gst_mel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved: test_generated_e2e.wav\n"
     ]
    }
   ],
   "source": [
    "y_g_hat = vocoder(mel.unsqueeze(0))\n",
    "audio = y_g_hat.squeeze()\n",
    "audio = audio * MAX_WAV_VALUE\n",
    "audio = audio.detach().cpu().numpy().astype('int16')\n",
    "\n",
    "output_file = 'test_generated_e2e.wav'\n",
    "write(output_file, 22050, audio)\n",
    "print(f'saved: {output_file}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
